{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NAME = \"\" # put your full name here\n",
    "COLLABORATORS = [] # list names of anyone you worked with on this homework."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [ER-131] Homework 2: Pandas EPA Air Quality\n",
    "\n",
    "---\n",
    "\n",
    "## Table of Contents\n",
    "[Introduction](#intro)<br>\n",
    "1 - [Downloading the Data](#data)<br>\n",
    "2 - [Preparing the Data](#prep)<br>\n",
    "3 - [Exploring Data with Pandas](#explore)<br>\n",
    "4 - [California Data](#cadata)<br>\n",
    "\n",
    "# Introduction <a id='intro'></a>\n",
    "\n",
    "In this homework, we will investigate air quality data retreived from the EPA and use Pandas to analyze particulate matter (PM2.5) levels.\n",
    "\n",
    "### Topics Covered\n",
    "\n",
    "As we clean and explore these data, you will gain practice with:\n",
    "* Manipulating tables and parts of the table (column, index)\n",
    "* Identifying the type of data collected, missing values, anomalies, etc.\n",
    "* Performing numeric operations (mean, variance)\n",
    "* Merging and analyzing data sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "## Section 1: Downloading the Data<a id='data'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the cell below to import some of the packages we will need for this assignment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run this cell\n",
    "from pathlib import Path\n",
    "import sys\n",
    "import math\n",
    "import zipfile\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1.1:** Import the Pandas and NumPy libraries `as` their commonly used abbreviations (i.e., `pd`, `np`).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll be working with air quality data from the EPA. Have a look at the description of the data  [here](https://aqs.epa.gov/aqsweb/airdata/FileFormats.html#_hourly_data_files).\n",
    "\n",
    "For this homework, we'll focus on PM2.5 Mass data from 2018. Although it's possible to download the dataset exclusively through the notebook environment, the dataset is too large (over 4 million rows, 1.3GB!) to load and process in DataHub given the memory constraint. Thus, we'll work with a preprocessed, reduced version of this dataset that removes readings from certain states that we will not be working with.**\n",
    "\n",
    "\n",
    "**For your future reference, the raw data can be downloaded from [this website](https://aqs.epa.gov/aqsweb/airdata/download_files.html). Alternatively, you can directly download a zipfile using a URL in the following form:\n",
    "\n",
    "https://aqs.epa.gov/aqsweb/airdata/hourly_TYPE_YEAR.zip\n",
    "\n",
    "...replacing \"TYPE\" and \"YEAR\" with the measurement and year, respectively, that you want to analyze.\n",
    "\n",
    "**Measurement | (TYPE)**  \n",
    "Ozone | (44201)  \n",
    "SO2 | (42401)  \n",
    "CO | (42101)  \n",
    "NO2 | (42602)  \n",
    "PM2.5 FRM/FEM Mass | (88101)  \n",
    "PM2.5 non FRM/FEM Mass | (88502)  \n",
    "PM10 Mass | (81102)  \n",
    "PM2.5 Speciation | (SPEC)  \n",
    "PM10 Speciation | (PM10SPEC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start by using Python to unzip the folder and see how many files it contains:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "air_quality_path = Path('data/reduced_PM25_2018.zip')\n",
    "zf = zipfile.ZipFile(air_quality_path, 'r')\n",
    "print([f.filename for f in zf.filelist])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that there is only one CSV file within the zip file. From here, we want to then get a sense of the structure of the data within the CSV.\n",
    "\n",
    "**Question 1.2:** Read the CSV file from the zip."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_name = ...  # REPLACE ELLIPSIS WITH YOUR CODE\n",
    "with zf.open(f_name) as f:\n",
    "    for i in range(2):\n",
    "        print(f.readline().rstrip().decode())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1.3:** In the code above, what does `i` represent in the `for` statement? (In other words, what is the `for` statement iterating over?)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*YOUR ANSWER HERE*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We can then organize this data and read it more easily by putting it in a table! We will go over this in the next section."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "## Section 2: Preparing the Data<a id='prep'></a>\n",
    "\n",
    "We can see that the file contains a pretty descriptive header, and in fact the columns are explained in detail in the documentation at the url listed at the top of this notebook. Let's extract the data into a Pandas dataframe. We will keep using `zf` to read the file and extract the information.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "with zf.open(f_name) as fh:\n",
    "    PM25_2018 = pd.read_csv(fh, low_memory = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PM25_2018.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2.1:** Look through the dataframe. Name three data types that it holds. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*YOUR ANSWER HERE*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2.2:** Identify at least one issue relating to questionable or missing data in the dataframe, and outline (in one sentence) how this data-related issue could impact an analyst's ability to draw conclusions from the data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*YOUR ANSWER HERE*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2.3:** Answer the questions below. (*Hint*: the method `.shape` might be helpful for answering the first two questions.)\n",
    "\n",
    "1. How many records are present?\n",
    "2. How many fields are reported?\n",
    "3. What does each row represent?\n",
    "4. After reading up on the data formats [here](https://aqs.epa.gov/aqsweb/airdata/FileFormats.html#_hourly_data_files), what does MDL stand for and what is it?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use this cell for scratch work\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*YOUR ANSWER HERE*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2.4:** What percentage of the records in the PM25_2018 dataframe have a smaller sample measurement than they do an MDL value? Are you more or less confident in those values than you are in the sample measurement values in the rest of the dataset? Why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use this cell for scratch work\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*YOUR ANSWER HERE*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2.5:** How many unique states are represented in `PM25_2018`? Which ones are they?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scratch work here\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*YOUR ANSWER HERE*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2.6:** We can see that there are a lot of columns that are unnecessary for this data analysis. Let's make a new dataframe with the information we need. Use pd.DataFrame to create a new table with 7 columns, named and ordered as follows:\n",
    "1. `State`: The name of the state where the monitoring site is located.\n",
    "1. `County`: The name of the county where the monitoring site is located.\n",
    "1. `Date`: The column of dates corresponding to the `Date Local` column.\n",
    "1. `Time`: The time of day that sampling began on a 24-hour clock, corresponding to the `Time Local` column.\n",
    "1. `Measurement`: The measured value in the standard units of measure for the parameter corresponding to the `Sample Measurement` column.\n",
    "1. `Units`: The unit of measure for the parameter corresponding to the `Units of Measure` column.\n",
    "1. `MDL`: the method detection limit for the measurement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "\n",
    "state_table = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run this cell\n",
    "state_table.iloc[80:90,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2.7a:** Within the `state_table` dataframe, find any rows where \"Measurement\" is lower than \"MDL.\" Replace the value in \"Measurement\" in those rows with `np.nan` (the `.loc` method is helpful here!).  \n",
    "\n",
    "*Hint / Warning*: You may get a \"SettingWithCopyWarning\".  It's ok to ignore.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run this cell\n",
    "state_table.iloc[80:90,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2.7b:** We could have used a different strategy to 'clean' the measurements with values below the MDL. Why might it be a good idea to replace these measurements with \"NaN\" rather than setting them to a numeric value, e.g., 0 or to the MDL? Similarly, why might we want to use \"NaN\" instead of removing these rows from the table entirely?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*YOUR ANSWER HERE*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "----\n",
    "\n",
    "## Section 3: Exploring Data with Pandas<a id='explore'></a>\n",
    "\n",
    "The air quality in Los Angeles, CA is notoriously poor. In this section we will analyze the EPA data to examine how air pollution varies over the course of the day."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3.1:** Using the table from Question 2.6, create a new table containing just data from Los Angeles county in California."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "lacounty = ... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lacounty.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(lacounty) == 15313"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3.2:** Below, output all the measurements in `lacounty` taken at midnight and all the measurements taken at noon. What do you notice?  You might try using the `.describe` method to explore your midnight and noon outputs separately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# measurements at midnight\n",
    "\n",
    "#YOUR CODE HERE\n",
    "la_midnight = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Measurements at noon\n",
    "\n",
    "# YOUR CODE HERE\n",
    "la_noon = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*YOUR OBSERVATIONS HERE*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3.4a:** We can also visualize this data and see how the PM2.5 concentrations fluctuate throughout the day. Start by using the `groupby` method to find the mean PM2.5 measurement for each hour of the day. Your output should be a dataframe in which the indices are the 24 hours of the day (00:00 - 23:00) and the columns are `Measurement` and `MDL`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "la_hr = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert la_hr.shape == (24, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3.3b:** Now, run the code in the cell below to plot the mean PM2.5 for each hour. The x-axis should be the hour of the day (00:00 - 23:00). Label the y-axis. Are there any noticeable trends in this plot?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(la_hr.index, la_hr['Measurement'])\n",
    "plt.xticks(rotation=270)\n",
    "plt.title('Average hourly PM2.5 concentration in Los Angeles County, 2018')\n",
    "plt.xlabel('Hour')\n",
    "# ADD A Y-AXIS LABEL\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*YOUR OBSERVATIONS HERE*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3.4a:** Use the `groupby` method on the `lacounty` dataframe once again, but this time, use the standard deviation (`std()`) aggregation function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "la_hr_stdev = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3.4b:** Run the code below to plot the standard deviation on the same graph as the mean data. Label the y-axis and title the plot. Record your observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(la_hr.index, la_hr['Measurement'], label = 'Mean')\n",
    "plt.plot(la_hr_stdev.index, la_hr_stdev['Measurement'], 'k:', label = 'Standard Deviation')\n",
    "plt.xticks(rotation=270)\n",
    "plt.xlabel('Hour')\n",
    "plt.legend()\n",
    "# LABEL THE Y-AXIS\n",
    "# ADD A TITLE\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*YOUR OBSERVATIONS HERE*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3.5:** Do the data support the hypothesis that PM2.5 concentrations follow a diurnal pattern? Why or why not? What are some of the limitations of either our data or the methods we've used to explore it so far in allowing us to observe hourly trends?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*YOUR ANSWER HERE*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3.6:** In Susan Athey's essay \"Beyond Prediction\", Athey defines the distinction between prediction problems and causal inference problems. Thinking about this air quality dataset, can you come up with one question that poses a prediction problem (also referred to a resource allocation problem in the essay) and another that poses a causal inference problem? The two questions you come up with should be air quality related, but you don't have to limit yourself to this dataset (eg. it's totally fair to come up with a question that would also incorporate, for example, census or demographic data)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*YOUR ANSWER HERE*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "## Section 4: California Data<a id='cadata'></a>\n",
    "\n",
    "Let's explore the dynamics of wildfire and air quality. In this section, we will use data analysis to see how a major wildfire impacted PM2.5 cocentrations in Alameda County. \n",
    "\n",
    "<br>**Question 4.1:** Create a dataframe called `PM25_2018_CA` that is a subset of `state_table` and just has PM2.5 2018 data for California."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "PM25_2018_CA = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PM25_2018_CA.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>**Question 4.2:** Use `groupby` to find the maximum PM2.5 concentration in each county in 2018. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "The Camp Fire, which started on November 8, 2018, was described as the [‘deadliest, most destructive wildfire in California history’](https://www.washingtonpost.com/nation/2018/11/25/camp-fire-deadliest-wildfire-californias-history-has-been-contained/?noredirect=on).\n",
    "\n",
    "UC Berkeley students could smell and see the effects of the fires in Butte County; classes were cancelled on November 15 due to poor air quality."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 4.3:** Using `PM25_2018_CA`, create a table containing just information from Alameda County on November 15, 2018."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "ac_nov15 = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ac_nov15.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 4.4:** Using `PM25_2018_CA`, create a table containing just information from Alameda County on November 7, 2018."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "ac_nov7 = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ac_nov7.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 4.5:** Merge `napa_nov15` and `napa_nov7` on `Time` to compare their PM2.5 concentrations side by side.\n",
    "\n",
    "*Note:* If  two dataframes have the same column names when pandas executes a merge, it will append a '_x' to the first dataframe's column names and a '_y' to the second dataframe's column names.  The rename operation is meant to clarify things.  Be sure that it's renaming correctly!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ac_merge = ... # YOUR CODE HERE\n",
    "ac_merge.rename(columns={'Measurement_x':'Nov15 PM2.5', 'Measurement_y':'Nov7 PM2.5'}, inplace = True)\n",
    "ac_merge.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 4.7:** Calculate the mean PM2.5 measurement on both days. Using [EPA's air quality index](https://www.airnow.gov/aqi/aqi-basics/), comment on the relative level of health concern for each day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*YOUR ANSWER HERE*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "## Submission\n",
    "\n",
    "Congrats, you're done with homework 2!\n",
    "\n",
    "Before you submit, click **Kernel** --> **Restart & Clear Output**. Then, click **Cell** --> **Run All**. Then, go to the toolbar and click **File** -> **Download as** -> **.html** and submit the file through bCourses."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "----\n",
    "\n",
    "## Bibliography\n",
    "\n",
    "\n",
    "- Washington Post - Camp Fire. https://www.washingtonpost.com/nation/2018/11/25/camp-fire-deadliest-wildfire-californias-history-has-been-contained/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Adapted from a notebook developed by: Melissa Ly\n",
    "\n",
    "Data Science Modules: http://data.berkeley.edu/education/modules"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
